{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"mps\"\n",
    "def generate_grid_edges(n, m):\n",
    "    edges = []\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            current = i * m + j\n",
    "            if i > 0: edges.append((current, (i - 1) * m + j, \"north\"))\n",
    "            if i < n - 1: edges.append((current, (i + 1) * m + j, \"south\"))\n",
    "            if j < m - 1: edges.append( (current, i * m + (j + 1), \"east\"))\n",
    "            if j > 0: edges.append((current, i * m + (j - 1), \"west\"))# West edge\n",
    "\n",
    "    return {\"edges\": edges}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/ms/qbhhrxd119555wkjspljcjcc0000gn/T/ipykernel_47606/196168407.py\", line 31, in <module>\n",
      "    *xt, x0  = samples(model, schedule.sample_sigmas(200), gam=2, cond = cond, batchsize = batchsize, xt = xt)\n",
      "  File \"/Users/sunyiqi/Documents/GitHub/MetaLearner/core/spatial/diffusion.py\", line 217, in samples\n",
      "    eps_prev, eps = eps, model.predict_eps_cfg(xt, sig.to(xt), cond, cfg_scale)\n",
      "  File \"/Users/sunyiqi/Documents/GitHub/MetaLearner/core/spatial/energy_graph.py\", line 49, in predict_eps_cfg\n",
      "    return self.predict_eps(x, sigma, cond)\n",
      "  File \"/Users/sunyiqi/Documents/GitHub/MetaLearner/core/spatial/energy_graph.py\", line 40, in predict_eps\n",
      "    return self(x, sigma, cond=cond)[\"gradient\"]\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/sunyiqi/Documents/GitHub/MetaLearner/core/spatial/energy_graph.py\", line 264, in forward\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/sunyiqi/Documents/GitHub/MetaLearner/core/spatial/energy_graph.py\", line 204, in forward\n",
      "    energy = self.net(nn_input).squeeze(-1)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "RuntimeError: linear(): input and weight.T shapes cannot be multiplied (64x4 and 6x16)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/anaconda3/envs/soulforge/lib/python3.9/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from core.spatial.energy_graph import PointEnergyMLP\n",
    "from core.spatial.diffusion import samples, ScheduleLogLinear, training_loop\n",
    "\n",
    "\n",
    "constraints = {\n",
    "    \"north\": [2, 2],\n",
    "    \"south\": [2, 2],\n",
    "    \"east\":  [2, 2],\n",
    "    \"west\":  [2, 2],\n",
    "    \"northeast\": [2, 2],\n",
    "    \"northwest\": [2, 2],\n",
    "    \"southeast\": [2, 2],\n",
    "    \"southwest\": [2, 2]\n",
    "    }\n",
    "\n",
    "state_path = \"outputs/checkpoints/direction_state.pth\"\n",
    "\n",
    "model = PointEnergyMLP(constraints, dim = 2)\n",
    "model.load_state_dict(torch.load(state_path, map_location = device))\n",
    "\n",
    "\n",
    "schedule = ScheduleLogLinear(N=200, sigma_min=0.005, sigma_max=10)\n",
    "#trainer  = training_loop(loader, model, schedule, epochs=000)\n",
    "#losses   = [ns.loss.item() for ns in trainer]\n",
    "\n",
    "n, m = (8,5)\n",
    "cond = generate_grid_edges(n, m)\n",
    "batchsize = n * m\n",
    "\n",
    "xt = torch.randn([1,batchsize,2])  * schedule.sample_sigmas(200)[0]\n",
    "*xt, x0  = samples(model, schedule.sample_sigmas(200), gam=2, cond = cond, batchsize = batchsize, xt = xt)\n",
    "\n",
    "print(\"Solution:\")\n",
    "print(x0[0].cpu().detach().numpy())\n",
    "\n",
    "from domains.spatial.direction_domain import direction_executor\n",
    "direction_executor.visualize(x0[0].cpu(), \"outputs/dir_cons\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SwissLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/50000 [00:00<55:25, 15.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/50000 [00:00<13:04, 63.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 54/50000 [00:00<09:22, 88.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 78/50000 [00:01<08:13, 101.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/50000 [00:01<08:20, 99.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 122/50000 [00:01<08:09, 101.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 146/50000 [00:01<07:42, 107.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmoving_average\u001b[39m(x, w):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconvolve(x, np\u001b[38;5;241m.\u001b[39mones(w), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m w\n\u001b[0;32m---> 26\u001b[0m losses   \u001b[38;5;241m=\u001b[39m [ns\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m ns \u001b[38;5;129;01min\u001b[39;00m trainer]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(moving_average(losses, \u001b[38;5;241m100\u001b[39m))\n",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmoving_average\u001b[39m(x, w):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconvolve(x, np\u001b[38;5;241m.\u001b[39mones(w), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m w\n\u001b[0;32m---> 26\u001b[0m losses   \u001b[38;5;241m=\u001b[39m [\u001b[43mns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m ns \u001b[38;5;129;01min\u001b[39;00m trainer]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(moving_average(losses, \u001b[38;5;241m100\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 146/50000 [00:20<07:42, 107.90it/s]"
     ]
    }
   ],
   "source": [
    "from core.spatial.energy_graph import PointEnergyMLP\n",
    "from core.spatial.diffusion import samples, ScheduleLogLinear, training_loop, ScheduleDDPM\n",
    "\n",
    "\n",
    "s_constraints = {\n",
    "    \"online\" : [2]\n",
    "}\n",
    "model = PointEnergyMLP(s_constraints, dim = 2)\n",
    "\n",
    "#model.load_state_dict(torch.load(\"outputs/checkpoints/state.pth\", map_location = \"cpu\"))\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets.ccsp_dataset import Swissroll, collate_graph_batch\n",
    "dataset = Swissroll(-10,10,N = 200)\n",
    "loader = DataLoader(dataset, batch_size = 1000, collate_fn = collate_graph_batch)\n",
    "\n",
    "schedule = ScheduleLogLinear(N=200, sigma_min=0.002, sigma_max=10)\n",
    "#schedule = ScheduleDDPM(N = 200, beta_start = 0.0001, beta_end = 0.02)\n",
    "trainer  = training_loop(loader, model, schedule, epochs=50000, lr = 0.001)\n",
    "\n",
    "import numpy as np\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "\n",
    "losses   = [ns.loss.item() for ns in trainer]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(moving_average(losses, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'schedule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m batchsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m160\u001b[39m\n\u001b[1;32m      3\u001b[0m cond \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m\"\u001b[39m:[(i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monline\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batchsize)]}\n\u001b[0;32m----> 5\u001b[0m xt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn([\u001b[38;5;241m1\u001b[39m,batchsize,\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[43mschedule\u001b[49m\u001b[38;5;241m.\u001b[39msample_sigmas(\u001b[38;5;241m100\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;241m*\u001b[39mxt, x0  \u001b[38;5;241m=\u001b[39m samples(model, schedule\u001b[38;5;241m.\u001b[39msample_sigmas(\u001b[38;5;241m100\u001b[39m), gam\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m, cond \u001b[38;5;241m=\u001b[39m cond, batchsize \u001b[38;5;241m=\u001b[39m batchsize, xt \u001b[38;5;241m=\u001b[39m xt)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot_batch\u001b[39m(batch):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'schedule' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "batchsize = 160\n",
    "cond = {\"edges\":[(i, \"online\") for i in range(batchsize)]}\n",
    "\n",
    "xt = torch.randn([1,batchsize,2]) * schedule.sample_sigmas(100)[0]\n",
    "*xt, x0  = samples(model, schedule.sample_sigmas(100), gam=1., cond = cond, batchsize = batchsize, xt = xt)\n",
    "\n",
    "def plot_batch(batch):\n",
    "    batch = batch.cpu().numpy()\n",
    "    plt.scatter(batch[:,0], batch[:,1], marker='.')\n",
    "print(x0.shape)\n",
    "plot_batch(x0[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soulforge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
